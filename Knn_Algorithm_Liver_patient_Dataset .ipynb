{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn import neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Indian Liver Patient Dataset (ILPD).csv\")\n",
    "df=df.fillna(-99999) #filling all missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K nearest neighbor algorithm\n",
    "def knn(data,predict,k=3):\n",
    "    if len(data)>=k:\n",
    "        print(\"WARNING: Number of classification is larger than k\")\n",
    "        \n",
    "    k_nearest_groups=[]\n",
    "    for i in data:\n",
    "        for feature in data[i]:\n",
    "            ecludian_distance= np.sum((np.array(feature)-np.array(predict))**2) #not taking sqrt to reduce time complexity\n",
    "            if(len(k_nearest_groups)<k):\n",
    "                k_nearest_groups.append((i,ecludian_distance))\n",
    "            else:\n",
    "                maxm=max(k_nearest_groups,key=itemgetter(1))\n",
    "                if(maxm[1]>ecludian_distance): #check if it finds the closest neighbor\n",
    "                    k_nearest_groups[k_nearest_groups.index(maxm)]=(i,ecludian_distance)\n",
    "    \n",
    "    get_k_nearest_groups=[i[0] for i in k_nearest_groups]\n",
    "    majority=Counter(get_k_nearest_groups).most_common(1)[0]           \n",
    "    \n",
    "    return majority[0], majority[1]/k #returning the nearest group with confidence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data set\n",
    "def fit(x,y,test_size=0.2):\n",
    "    \n",
    "    x_tr,x_te,y_tr,y_te=x[:-int(test_size*len(x))],x[-int(test_size*len(x)):],y[:-int(test_size*len(x))],y[-int(test_size*len(x)):]\n",
    "    x_train={1:[],2:[]}\n",
    "    x_test={1:[],2:[]}\n",
    "\n",
    "    for i in range(len(x_tr)):\n",
    "        x_train[y_tr[i]].append(x_tr[i])\n",
    "\n",
    "    for i in range(len(x_te)):\n",
    "        x_test[y_te[i]].append(x_te[i])\n",
    "    \n",
    "    return x_train,x_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_train,data,k=5):\n",
    "    return knn(x_train,data,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict and give total accuracy\n",
    "def score(x_train,x_test):\n",
    "    correct=0\n",
    "    total=0\n",
    "    for grp in x_test:\n",
    "        for data in x_test[grp]:\n",
    "            grp_pred,confidence=knn(x_train,data,5)\n",
    "            if grp_pred==grp:\n",
    "                correct+=1\n",
    "            total+=1\n",
    "    return correct/total    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(df.drop(['class'],1))\n",
    "y=np.array(df['class'])\n",
    "x_train,x_test=fit(x,y)\n",
    "acc=score(x_train,x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0.6)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(x_train,x_te[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr,x_te,y_tr,y_te=x[:-int(0.2*len(x))],x[-int(0.2*len(x)):],y[:-int(0.2*len(x))],y[-int(0.2*len(x)):]\n",
    "model=neighbors.KNeighborsClassifier()\n",
    "model.fit(x_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn Model's Accuracy:  0.7413793103448276 \n",
      "Manually Calculated Accuracy:  0.7413793103448276\n"
     ]
    }
   ],
   "source": [
    "print(\"Sklearn Model's Accuracy: \",model.score(x_te,y_te),\"\\nManually Calculated Accuracy: \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
